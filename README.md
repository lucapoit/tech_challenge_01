# ğŸ“š Books API â€” Web Scraping + API REST + ML

## ğŸ“ DescriÃ§Ã£o do Projeto

Este projeto consiste em uma soluÃ§Ã£o completa para coleta, exposiÃ§Ã£o e anÃ¡lise de dados de livros via Web Scraping, API RESTful e integraÃ§Ã£o com modelos de Machine Learning.

Os dados sÃ£o extraÃ­dos do site [Books to Scrape](https://books.toscrape.com/), processados e disponibilizados por meio de uma API desenvolvida com FastAPI.

---

## ğŸ”§ Estrutura do Projeto

.

â”œâ”€â”€ books.csv                 Arquivo CSV com os livros extraÃ­dos

â”œâ”€â”€ users.json                Arquivo json com os usuÃ¡rios com permissÃµes (idealmente invisÃ­vel)

â”œâ”€â”€ ml_model.py               Simula o modelo de ML

â”œâ”€â”€ basemodels.py             Classes usadas em outras partes do projeto

â”œâ”€â”€ auht_utils.py             FunÃ§Ãµes auxiliares de autenticaÃ§Ã£o

â”œâ”€â”€ db_utils.py               FunÃ§Ãµes auxiliares de interaÃ§Ã£o com o banco de dados

â”œâ”€â”€ api.py                    InicializaÃ§Ã£o da aplicaÃ§Ã£o FastAPI

â”œâ”€â”€ streamlit_dashboard.py    Gera o dashboard sobre o funcionamento da API

â”œâ”€â”€ requirements.txt          DependÃªncias

â”œâ”€â”€ Procfile                  Para deploy com Heroku

â”œâ”€â”€ .python-version           Para deploy com Heroku

â””â”€â”€ README.md

---

## ğŸš€ Como Executar Localmente

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/books-api.git
cd books-api
```

2. Crie e ative um ambiente virtual:
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Execute o Web Scraping:
```bash
python scripts/scraper.py
```

5. Inicie a API:
```bash
uvicorn main:app --reload
```

---

## ğŸ“š Endpoints da API

### Endpoints principais

- `GET /api/v1/books`: Lista todos os livros
- `GET /api/v1/books/{id}`: Retorna detalhes de um livro
- `GET /api/v1/books/search?title=...&category=...`: Busca por tÃ­tulo e/ou categoria
- `GET /api/v1/categories`: Lista todas as categorias
- `GET /api/v1/health`: Verifica status da API

### Endpoints de estatÃ­sticas (opcional)

- `GET /api/v1/stats/overview`: EstatÃ­sticas gerais (preÃ§o mÃ©dio, total de livros, etc.)
- `GET /api/v1/stats/categories`: EstatÃ­sticas por categoria
- `GET /api/v1/books/top-rated`: Lista os livros com melhor avaliaÃ§Ã£o
- `GET /api/v1/books/price-range?min=...&max=...`: Livros por faixa de preÃ§o

### Endpoints para ML (opcional)

- `GET /api/v1/ml/features`: Dados formatados para features
- `GET /api/v1/ml/training-data`: Dados completos para treinamento
- `POST /api/v1/ml/predictions`: Recebe dados e retorna uma prediÃ§Ã£o (fake)

### Endpoints protegidos (opcional)

- `POST /api/v1/auth/login`: Gera token JWT
- `POST /api/v1/scraping/trigger`: Executa novo scraping (rota protegida)

---

## âœ… Exemplo de RequisiÃ§Ã£o

```http
GET /api/v1/books/search?title=python
```

**Resposta:**
```json
[
  {
    "id": "23",
    "title": "Learning Python",
    "category": "Programming",
    "price": 45.90,
    "rating": 5,
    "availability": 20
  }
]
```

---

## ğŸ–¥ï¸ Deploy PÃºblico

A aplicaÃ§Ã£o estÃ¡ disponÃ­vel em produÃ§Ã£o neste link:

ğŸ‘‰ [https://tc-01-c70fbb49e587.herokuapp.com/docs#/](https://tc-01-c70fbb49e587.herokuapp.com/docs#/) 

---

## ğŸ§  Plano Arquitetural

- **IngestÃ£o de dados**: Web scraping automatizado (`scraper.py`)
- **Processamento**: Dados armazenados em CSV
- **API REST**: Disponibiliza os dados via FastAPI
- **ML Ready**: Endpoints simulando prediÃ§Ãµes e extraÃ§Ã£o de features
- **EscalÃ¡vel**: Estrutura modular, fÃ¡cil de manter e expandir
- **Monitoramento**: Dashboard de monitoramento disponÃ­vel em [https://tech-challenge-001.streamlit.app/](https://tech-challenge-001.streamlit.app/)

---

## ğŸ“¹ ApresentaÃ§Ã£o

VÃ­deo explicativo com execuÃ§Ã£o de chamadas reais e explicaÃ§Ã£o da arquitetura disponÃ­vel [aqui](#).

---

## ğŸ‘¨â€ğŸ”§ Autor

Este projeto foi desenvolvido como parte de um Tech Challenge.
